[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity)
[![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com) 
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![](https://img.shields.io/github/last-commit/richard-peng-xia/awesome-vision-language-prompt?color=green) 
![](https://img.shields.io/badge/PaperNumber-92-brightgreen)

# awesome-vision-language-prompt
A collection of resources on applications of prompt learning in vision-language models.

## Contributing
Please feel free to send me [pull requests](https://github.com/richard-peng-xia/awesome-multimodal-in-medical-imaging/pulls) or email (richard.peng.xia@gmail.com) to add links or to discuss with me about this area.
Markdown format:
```markdown
- [**Name of Conference or Journal + Year**] Paper Name. [[pdf]](link) [[code]](link)
```

## Vision-Language Prompt ![](https://img.shields.io/badge/Vision_Language_Prompt-green)
- [**arXiv 2022**] Towards Visual-Prompt Temporal Answering Grounding in Medical Instructional Video [[pdf]](https://arxiv.org/pdf/2203.06667)
- [**CVPR 2022**] LAVT: Language-Aware Vision Transformer for Referring Image Segmentation [[pdf]](https://arxiv.org/pdf/2112.02244) [[code]](https://github.com/yz93/lavt-ris)
- [**CVPR 2022**] Image Segmentation Using Text and Image Prompts [[pdf]](https://arxiv.org/pdf/2112.10003) [[code]](https://github.com/timojl/clipseg)
- [**IJCV 2022**] Learning to Prompt for Vision-Language Models [[pdf]](https://arxiv.org/pdf/2109.01134) [[code]](https://github.com/kaiyangzhou/coop)
- [**CVPR 2022**] Conditional Prompt Learning for Vision-Language Models [[pdf]](https://arxiv.org/pdf/2203.05557) [[code]](https://github.com/kaiyangzhou/coop)
- [**arXiv 2022**] Neural Prompt Search [[pdf]](https://arxiv.org/pdf/2206.04673) [[code]](https://github.com/Davidzhangyuanhan/NOAH)
- [**CVPR 2022**] Prompt-RSVQA: Prompting Visual Context to a Language Model for Remote Sensing Visual Question Answering [[pdf]](https://openaccess.thecvf.com/content/CVPR2022W/EarthVision/papers/Chappuis_Prompt-RSVQA_Prompting_Visual_Context_to_a_Language_Model_for_Remote_CVPRW_2022_paper.pdf) 
- [**arXiv 2022**] Prompt-to-Prompt Image Editing with Cross Attention Control [[pdf]](https://arxiv.org/pdf/2208.01626)
- [**arXiv 2022**] Prompt Tuning for Generative Multimodal Pretrained Models [[pdf]](https://arxiv.org/pdf/2208.02532) [[code]](https://github.com/OFA-Sys/OFA)
- [**arXiv 2022**] P2P: Tuning Pre-trained Image Models for Point Cloud Analysis with Point-to-Pixel Prompting [[pdf]](https://arxiv.org/pdf/2208.02812.pdf) [[code]](https://github.com/wangzy22/P2P)
- [**arXiv 2022**] MILAN: Masked Image Pretraining on Language Assisted Representation [[pdf]](https://arxiv.org/pdf/2208.06049) [[code]](https://github.com/zejiangh/MILAN)
- [**arXiv 2022**] Class-Aware Visual Prompt Tuning for Vision-Language Pre-Trained Model [[pdf]](https://arxiv.org/pdf/2208.08340.pdf)
- [**arXiv 2022**] Prompt Vision Transformer for Domain Generalization [[pdf]](https://arxiv.org/pdf/2208.08914.pdf)
- [**arXiv 2022**] Prompt-Matched Semantic Segmentation [[pdf]](https://arxiv.org/pdf/2208.10159)
- [**ECCV 2022**] Learning from Unlabeled 3D Environments for Vision-and-Language Navigation [[pdf]](https://arxiv.org/pdf/2208.11781.pdf) [[code]](https://cshizhe.github.io/projects/hm3d_autovln.html)
- [**arXiv 2022**] Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task [[pdf]](https://arxiv.org/pdf/2208.12037.pdf) [[code]](https://github.com/showlab/CLVQA) 
- [**arXiv 2022**] Prompt Tuning with Soft Context Sharing for Vision-Language Models [[pdf]](https://arxiv.org/pdf/2208.13474.pdf)
- [**ICLR 2023**] Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models [[pdf]](https://arxiv.org/pdf/2209.07511.pdf) [[code]](https://azshue.github.io/TPT/)
- [**NeurIPS 2022**] Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models [[pdf]](https://arxiv.org/pdf/2209.06970.pdf) [[code]](https://github.com/ChenWu98/Generative-Visual-Prompt)
- [**NeurIPS 2022**] M^4I: Multi-modal Models Membership Inference [[pdf]](https://arxiv.org/pdf/2209.06997.pdf) [[code]](https://github.com/MultimodalMI/Multimodal-membership-inference)
- [**IJCAI 2022**] Declaration-based Prompt Tuning for Visual Question Answering [[pdf]](https://arxiv.org/pdf/2205.02456) [[code]](https://github.com/CCIIPLab/DPT)
- [**MICCAI 2022**] Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training [[pdf]](https://arxiv.org/pdf/2209.07098.pdf) [[code]](https://github.com/zhjohnchan/M3AE)
- [**NeurIPS 2022**] GLIPv2: Unifying Localization and VL Understanding [[pdf]](https://arxiv.org/pdf/2206.05836.pdf) [[code]](https://github.com/microsoft/GLIP)
- [**ICLR 2023**] Medical Image Understanding with Pretrained Vision Language Models: A Comprehensive Study [[pdf]](https://arxiv.org/pdf/2209.15517)
- [**arXiv 2022**] Language-Aware Soft Prompting for Vision & Language Foundation Models [[pdf]](https://arxiv.org/pdf/2210.01115)
- [**ICLR 2023**] LPT: Long-tailed Prompt Tuning for Image Classification [[pdf]](https://arxiv.org/pdf/2210.01033)
- [**arXiv 2022**] Prompt Learning with Optimal Transport for Vision-Language Models [[pdf]](https://arxiv.org/pdf/2210.01253)
- [**arXiv 2022**] Variational prompt tuning improves generalization of vision-language models [[pdf]](https://arxiv.org/pdf/2210.02390)
- [**CVPR 2023**] MaPLe: Multi-modal Prompt Learning [[pdf]](https://arxiv.org/pdf/2210.03117) [[code]](https://github.com/muzairkhattak/multimodal-prompt-learning)
- [**arXiv 2022**] Learning to Decompose Visual Features with Latent Textual Prompts [[pdf]](https://arxiv.org/pdf/2210.04287)
- [**arXiv 2022**] Visual Prompting for Adversarial Robustness [[pdf]](https://arxiv.org/pdf/2210.06284) 
- [**arXiv 2022**] Unified Vision and Language Prompt Learning [[pdf]](https://arxiv.org/pdf/2210.07225) [[code]](https://github.com/yuhangzang/upt)
- [**EMNLP 2022**] CPL: Counterfactual Prompt Learning for Vision and Language Models [[pdf]](https://arxiv.org/pdf/2210.10362.pdf)
- [**arXiv 2022**] Prompting through Prototype: A Prototype-based Prompt Learning on Pretrained Vision-Language Models [[pdf]](https://arxiv.org/pdf/2210.10841.pdf)
- [**arXiv 2022**] Understanding and Mitigating Overfitting in Prompt Tuning for Vision-Language Models [[pdf]](https://arxiv.org/pdf/2211.02219.pdf) [[code]](https://github.com/machengcheng2016/Subspace-Prompt-Learning)
- [**arXiv 2022**] Multitask Vision-Language Prompt Tuning [[pdf]](https://arxiv.org/pdf/2211.11720) [[code]](https://github.com/sIncerass/MVLPT)
- [**arXiv 2022**] ProSFDA: Prompt Learning based Source-free Domain Adaptation for Medical Image Segmentation [[pdf]](https://arxiv.org/pdf/2211.11514) [[code]](https://github.com/ShishuaiHu/ProSFDA)
- [**arXiv 2022**] PromptCap: Prompt-Guided Task-Aware Image Captioning [[pdf]](https://arxiv.org/pdf/2211.09699)
- [**arXiv 2022**] Prompt Tuning for Parameter-efficient Medical Image Segmentation [[pdf]](https://arxiv.org/pdf/2211.09233) [[code]](https://github.com/marcdcfischer/PUNet)
- [**arXiv 2022**] Task Residual for Tuning Vision-Language Models [[pdf]](https://arxiv.org/pdf/2211.10277.pdf) [[code]](https://github.com/geekyutao/TaskRes)
- [**AAAI 2023**] Controllable Image Captioning via Prompting [[pdf]](https://arxiv.org/pdf/2212.01803.pdf) 
- [**arXiv 2022**] See, Think, Confirm: Interactive Prompting Between Vision and Language Models for Knowledge-based Visual Reasoning [[pdf]](https://arxiv.org/pdf/2301.05226.pdf)
- [**arXiv 2022**] From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models [[pdf]](https://arxiv.org/pdf/2212.10846.pdf)
- [**CVPR 2023**] Position-guided Text Prompt for Vision-Language Pre-training [[pdf]](https://arxiv.org/pdf/2212.09737.pdf) [[code]](https://github.com/sail-sg/ptp)
- [**CVPR 2023**] Doubly Right Object Recognition: A Why Prompt for Visual Rationales [[pdf]](https://arxiv.org/pdf/2212.06202.pdf)
- [**arXiv 2022**] Unified vision and language prompt learning [[pdf]](https://arxiv.org/pdf/2210.07225.pdf) [[code]](https://github.com/yuhangzang/UPT)
- [**arXiv 2022**] Prompt Vision Transformer for Domain Generalization [[pdf]](https://arxiv.org/pdf/2208.08914)
- [**AAAI 2023**] Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation [[pdf]](https://arxiv.org/pdf/2212.04145.pdf)
- [**NeurIPS 2022**] DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited Annotations [[pdf]](https://arxiv.org/pdf/2206.09541.pdf) [[code]](https://github.com/sunxm2357/DualCoOp)
- [**ICLR 2023**] Visual Classification via Description from Large Language Models [[pdf]](https://arxiv.org/pdf/2210.07183.pdf)
- [**CVPR 2022**] Prompt Distribution Learning [[pdf]](http://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Prompt_Distribution_Learning_CVPR_2022_paper.pdf) 
- [**arXiv 2023**] StyLIP: Multi-Scale Style-Conditioned Prompt Learning for CLIP-based Domain Generalization [[pdf]](https://arxiv.org/pdf/2302.09251) 
- [**ICLR 2023**] Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video Relation Detection [[pdf]](https://arxiv.org/pdf/2302.00268) [[code]](https://github.com/Dawn-LX/OpenVoc-VidVRD)
- [**arXiv 2022**] Prompt Vision Transformer for Domain Generalization [[pdf]](https://arxiv.org/pdf/2208.08914) [[code]](https://github.com/zhengzangw/DoPrompt)
- [**CVPR 2023**] Multimodal Prompting with Missing Modalities for Visual Recognition [[pdf]](https://arxiv.org/pdf/2303.03369) [[code]](https://github.com/YiLunLee/Missing_aware_prompts)
- [**CVPR 2023**] Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering [[pdf]](https://arxiv.org/pdf/2303.01903) [[code]](https://github.com/MILVLG/prophet)
- [**CVPR 2023**] Turning a CLIP Model into a Scene Text Detector [[pdf]](https://arxiv.org/pdf/2302.14338) [[code]](https://github.com/wenwenyu/TCM)
- [**CVPR 2023**] Visual Prompt Multi-Modal Tracking [[pdf]](https://arxiv.org/pdf/2303.10826.pdf) [[code]](https://github.com/jiawen-zhu/ViPT)
- [**CVPR 2023**] Texts as Images in Prompt Tuning for Multi-Label Image Recognition [[pdf]](https://arxiv.org/pdf/2211.12739) [[code]](https://github.com/guozix/TaI-DPT)
- [**CVPR 2023**] PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for Generalized Novel Category Discovery [[pdf]](https://arxiv.org/pdf/2212.05590.pdf) [[code]](https://github.com/sheng-eatamath/PromptCAL)
- [**CVPR 2023**] LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision & Language Models [[pdf]](https://arxiv.org/pdf/2210.01115.pdf) [[code]](https://www.adrianbulat.com/lasp)
- [**CVPR 2023**] Visual-Language Prompt Tuning with Knowledge-guided Context Optimization [[pdf]](https://arxiv.org/pdf/2303.13283.pdf) [[code]](https://github.com/htyao89/KgCoOp)
- [**arXiv 2023**] What does CLIP know about a red circle? Visual prompt engineering for VLMs [[pdf]](https://arxiv.org/pdf/2304.06712)
- [**CVPR 2023**] Learning Instance-Level Representation for Large-Scale Multi-Modal Pretraining in E-commerce [[pdf]](https://arxiv.org/pdf/2304.02853)
- [**arXiv 2023**] SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger [[pdf]](https://arxiv.org/pdf/2303.17561.pdf)
- [**CVPR 2023**] Correlational Image Modeling for Self-Supervised Visual Pre-Training [[pdf]](https://arxiv.org/pdf/2303.12670.pdf) [[code]](https://github.com/weivision/Correlational-Image-Modeling)
- [**arXiv 2023**] Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition [[pdf]](https://arxiv.org/pdf/2304.04704) [[code]](https://github.com/amazon-science/prompt-pretraining)
- [**arXiv 2023**] Towards Robust Prompts on Vision-Language Models [[pdf]](https://arxiv.org/pdf/2304.08479.pdf)
- [**arXiv 2023**] Chain of Thought Prompt Tuning for Vision-Language Models [[pdf]](https://arxiv.org/pdf/2304.07919.pdf)
- [**arXiv 2023**] LMPT: Prompt Tuning with Class-Specific Embedding Loss for Long-tailed Multi-Label Visual Recognition [[pdf]](https://arxiv.org/pdf/2305.04536) [[code]](https://github.com/richard-peng-xia/LMPT)
- [**arXiv 2023**] Improved baselines for vision-language pre-training [[pdf]](https://arxiv.org/ftp/arxiv/papers/2305/2305.08675.pdf)
- [**CVPR 2023**] Open-set Fine-grained Retrieval via Prompting Vision-Language Evaluator [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Open-Set_Fine-Grained_Retrieval_via_Prompting_Vision-Language_Evaluator_CVPR_2023_paper.pdf)
- [**CVPR 2023**] Semantic Prompt for Few-Shot Image Recognition [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Semantic_Prompt_for_Few-Shot_Image_Recognition_CVPR_2023_paper.pdf)
- [**CVPR 2023**] Visual Prompt Tuning for Generative Transfer Learning [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Sohn_Visual_Prompt_Tuning_for_Generative_Transfer_Learning_CVPR_2023_paper.pdf) [[code]](https://github.com/google-research/generative_)
- [**CVPR 2023**] CORA: Adapting CLIP for Open-Vocabulary Detection With Region Prompting and Anchor Pre-Matching [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_CORA_Adapting_CLIP_for_Open-Vocabulary_Detection_With_Region_Prompting_and_CVPR_2023_paper.pdf) [[code]](https://github.com/tgxs002/CORA)
- [**CVPR 2023**] Efficient Multimodal Fusion via Interactive Prompting [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Efficient_Multimodal_Fusion_via_Interactive_Prompting_CVPR_2023_paper.pdf)
- [**CVPR 2023**] CODA-Prompt: COntinual Decomposed Attention-Based Prompting for Rehearsal-Free Continual Learning [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Smith_CODA-Prompt_COntinual_Decomposed_Attention-Based_Prompting_for_Rehearsal-Free_Continual_Learning_CVPR_2023_paper.pdf) [[code]](https://github.com/GT-RIPL/CODA-Prompt)
- [**CVPR 2023**] Hierarchical Prompt Learning for Multi-Task Learning [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Hierarchical_Prompt_Learning_for_Multi-Task_Learning_CVPR_2023_paper.pdf)
- [**CVPR 2023**] Visual Prompt Multi-Modal Tracking [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Visual_Prompt_Multi-Modal_Tracking_CVPR_2023_paper.pdf) [[code]](https://github.com/jiawen-zhu/ViPT)
- [**CVPR 2023**] ProD: Prompting-To-Disentangle Domain Knowledge for Cross-Domain Few-Shot Image Classification [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_ProD_Prompting-To-Disentangle_Domain_Knowledge_for_Cross-Domain_Few-Shot_Image_Classification_CVPR_2023_paper.pdf)
- [**CVPR 2023**] LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision & Language Models [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Bulat_LASP_Text-to-Text_Optimization_for_Language-Aware_Soft_Prompting_of_Vision__CVPR_2023_paper.pdf)
- [**CVPR 2023**] Decomposed Soft Prompt Guided Fusion Enhancing for Compositional Zero-Shot Learning [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Decomposed_Soft_Prompt_Guided_Fusion_Enhancing_for_Compositional_Zero-Shot_Learning_CVPR_2023_paper.pdf) [[code]](https://github.com/Forest-art/DFSP)
- [**CVPR 2023**] Learning Federated Visual Prompt in Null Space for MRI Reconstruction [[pdf]](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Learning_Federated_Visual_Prompt_in_Null_Space_for_MRI_Reconstruction_CVPR_2023_paper.pdf) [[code]](https://github.com/chunmeifeng/FedPR)
- [**arXiv 2023**] CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks [[pdf]](https://arxiv.org/pdf/2304.05653.pdf) [[code]](https://github.com/xmed-lab/CLIP_Surgery)
- [**arXiv 2023**] Exploring Vision-Language Models for Imbalanced Learning [[pdf]](https://arxiv.org/pdf/2304.01457.pdf) [[code]](https://github.com/Imbalance-VLM/Imbalance-VLM)
- [**arXiv 2023**] TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding [[pdf]](https://arxiv.org/pdf/2305.11497)
- [**arXiv 2023**] Fine-Grained Visual Prompting [[pdf]](https://arxiv.org/pdf/2306.04356)
- [**arXiv 2023**] ProTeCt: Prompt Tuning for Hierarchical Consistency [[pdf]](https://arxiv.org/pdf/2306.02240)
- [**arXiv 2023**] Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning [[pdf]](https://arxiv.org/pdf/2306.01669) [[code]](http://github.com/BatsResearch/menghini-enhanceCLIPwithCLIP-code)
- [**arXiv 2023**] Consistency-guided Prompt Learning for Vision-Language Models [[pdf]](https://arxiv.org/pdf/2306.01195)
- [**arXiv 2023**] LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning [[pdf]](https://arxiv.org/pdf/2306.01293) [[code]](https://github.com/AtsuMiyai/LoCoOp)
- [**arXiv 2023**] Deeply Coupled Cross-Modal Prompt Learning [[pdf]](https://arxiv.org/pdf/2305.17903) [[code]](https://github.com/GingL/CMPA)
